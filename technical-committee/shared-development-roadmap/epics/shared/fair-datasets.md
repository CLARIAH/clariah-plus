---
#(This frontmatter block follows YAML syntax)
id: fair-datasets #epic-title-in-lowercase-with-hyphens
coordinator: TODO #person or list of people
wp: [ 1, 2, 3, 4, 5, 6] #involved workpackages
github-projects-link: https://github.com/orgs/CLARIAH/projects/2 #link to a specific project under here
participants:
    - Willem Melder (NISV)
    - Jaap Blom (NISV)
    - tbd
themes: [ Datasets, Linked Data, Metadata, DevOps, Search, Sustainability]
evaluation: #overall evaluation for the (best) implementation of this epic
    trl: 0 #technology readiness level
    cl: 0 #compliance level
    srl: 0 #stakeholder readiness level
---

## FAIR Datasets

### Rationale

> Describe, from a high-level perspective, the rationale of what important role
> the service(s) that implement this epic fulfill in the CLARIAH infrastructure

In CLARIAH several datasets and dataset registries are currently available, but hosted & published in different
ways, making it hard for scholars to find or know about all available datasets. 

The goal of this epic is to TODO...


### User Stories

> Describe, from a high-level scholarly perspective and in minimal and generic terms, the user stories that define this epic.
> We recommend using sublists (i.e. a simple tree structure) for breaking down user stories into parts when needed.

1. **As a scholar, I** TODO

### Needs & Dependencies

> Describe organisational and technical dependencies that are crucial for the success of this service.

* Compliance to the software/infrastructure requirements as described in the next section
* Cross-WP agreement on the dataset metadata model (e.g. DCAT)
* Cross-WP agreement on the dataset registry software to be promoted and used
* TODO

### Requirements

> Describe software, infrastructure & interoperability requirements that arise from this service or that are especially relevant for this service. These must be formulated in further detail in the corresponding requirements documents.

* Dataset registries MUST define CodeMeta software metadata along with the source code
* Registered datasets SHOULD include a link to a publicly accessible API
* TODO
* TODO

### Service Description

> Describe the service(s) that implement(s) this epic, mention software components, data components and interoperability standards where appropriate.

TODO

### Components

> Describe the components and subcomponents involved in this epic in a simple tree form; specify whether the component
> is: a service (instance), software, data, and estimate a TRL. Please consult the
> [definitions](introduction.md#definitions) and [data model](introduction.md#data-model). In case of multiple
> implementations, use multiple detached trees/lists and add a level four heading for each.


### Workflow Schema

> Draw a schema indicating how the various software and data components interact. This is required only when many
> components are involved and their connection is not immediately obvious.

### Evaluation

> Estimate the overall readiness of the implementation(s) for this epic in the frontmatter. You may add any additional
> evaluation here.

### Context

> Sketch the wider context of the implementations for this epic in relation to other (existing/proposed) projects and initiatives.



### Use cases

> Link to specific use cases for which this user story is relevant, use cases should reside in the [use cases directory](../../use-cases/)

### Planning

> A rough planning for this epic. The GitHub Projects kanban board for this epic should be used for more detailed planning during development

### Resources

> Resources? I don't really know what goes here yet


